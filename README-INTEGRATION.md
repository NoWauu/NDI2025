# ðŸŽ¯ Guide d'IntÃ©gration Frontend â†” Backend

**Date** : DÃ©cembre 2025
**Statut** : âœ… Merge Phase 1 Complet

---

## ðŸ“Š Vue d'ensemble

L'intÃ©gration entre le frontend UI et le backend IA est maintenant **fonctionnelle**. Le systÃ¨me utilise une architecture client-serveur oÃ¹ :

- **Frontend** (port 3000) : Interface utilisateur + Rules Engine fallback
- **Backend** (port 4000) : API HTTP + Moteur IA + Base de connaissances

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         HTTP          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  â”‚   POST /api/chat      â”‚                  â”‚
â”‚   Frontend UI    â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>  â”‚   Backend IA     â”‚
â”‚   (Port 3000)    â”‚                       â”‚   (Port 4000)    â”‚
â”‚                  â”‚ <â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚                  â”‚
â”‚  + Rules Engine  â”‚   JSON Response       â”‚  + KB + FAQ      â”‚
â”‚    (Fallback)    â”‚                       â”‚  + Prompting     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸš€ DÃ©marrage Rapide

### 1. DÃ©marrer le Backend IA

```bash
npm run backend
```

Le backend dÃ©marre sur **http://localhost:4000**

Vous devriez voir :
```
âœ… Backend IA ready on http://localhost:4000

Endpoints disponibles:
  - POST http://localhost:4000/api/chat
  - GET  http://localhost:4000/api/status
```

### 2. DÃ©marrer le Frontend

Dans un **nouveau terminal** :

```bash
npm run dev
```

Le frontend dÃ©marre sur **http://localhost:3000**

### 3. Tester l'application

Ouvrez votre navigateur sur **http://localhost:3000**

Le systÃ¨me est maintenant opÃ©rationnel avec :
- âœ… Backend IA actif
- âœ… Fallback Rules Engine
- âœ… Mode dÃ©gradÃ© automatique

---

## ðŸ” Architecture des Modules

### Backend (ES Modules)

```
ia/
â”œâ”€â”€ app.js              # Orchestrateur principal + generateIaResponse()
â”œâ”€â”€ data_loader.js      # Chargement KB + FAQ
â”œâ”€â”€ prompting.js        # Construction des prompts FR/AR
â”œâ”€â”€ rag.js              # Stub RAG (Phase 3)
â”œâ”€â”€ rag_pipeline.js     # Stub RAG Pipeline (Phase 3)
â””â”€â”€ llm.js              # Stub LLM (Phase 2)

server.js               # Serveur HTTP Express
```

### Frontend (ES Modules)

```
src/
â”œâ”€â”€ main.js             # Point d'entrÃ©e (CONFIG.ENABLE_AI = true)
â”œâ”€â”€ engine/
â”‚   â”œâ”€â”€ ai-adapter.js   # Appels HTTP vers backend
â”‚   â””â”€â”€ rules-engine.js # Fallback basÃ© sur mots-clÃ©s
â”œâ”€â”€ storage/
â”‚   â””â”€â”€ db-manager.js   # IndexedDB
â””â”€â”€ ui/
    â””â”€â”€ chat-ui.js      # Interface chat
```

---

## ðŸ”„ Flow de Conversation

### Cas 1 : Backend Actif

```
1. Utilisateur envoie "Comment obtenir une CNI ?"
   â†“
2. main.js â†’ handleUserMessage()
   â†“
3. isReady() = true (backend accessible)
   â†“
4. ai-adapter.js â†’ generateResponse()
   â†“
5. POST http://localhost:4000/api/chat
   {
     "message": "Comment obtenir une CNI ?",
     "language": "fr",
     "history": []
   }
   â†“
6. Backend â†’ generateIaResponse()
   - Charge KB + FAQ
   - Construit prompt avec contexte
   - Retourne rÃ©ponse formatÃ©e
   â†“
7. Frontend affiche la rÃ©ponse (source: 'ai')
```

### Cas 2 : Backend Inactif (Mode DÃ©gradÃ©)

```
1. Utilisateur envoie "Comment obtenir une CNI ?"
   â†“
2. main.js â†’ handleUserMessage()
   â†“
3. ai-adapter.js â†’ generateResponse()
   â†“
4. fetch() Ã©choue (backend down)
   â†“
5. Retourne null
   â†“
6. main.js â†’ fallback vers rules-engine
   â†“
7. rules-engine.js â†’ findAnswer()
   - Matching par mots-clÃ©s
   - Retourne FAQ statique
   â†“
8. Frontend affiche la rÃ©ponse (source: 'rules')
```

---

## ðŸ§ª Tests

### Test 1 : Backend seul

```bash
# DÃ©marrer le backend
npm run backend

# Tester l'API
curl http://localhost:4000/api/status

curl -X POST http://localhost:4000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Comment obtenir une carte d'\''identitÃ© ?", "language": "fr"}'
```

**RÃ©sultat attendu** : JSON avec `content`, `confidence`, `source`, `metadata`

### Test 2 : Frontend + Backend

```bash
# Terminal 1
npm run backend

# Terminal 2
npm run dev

# Navigateur : http://localhost:3000
# Poser une question dans le chat
```

**RÃ©sultat attendu** :
- Message utilisateur affichÃ©
- Indicateur de saisie "L'assistant rÃ©flÃ©chit..."
- RÃ©ponse IA affichÃ©e avec le prompt construit

### Test 3 : Mode dÃ©gradÃ©

```bash
# 1. ArrÃªter le backend (Ctrl+C dans terminal 1)

# 2. Continuer Ã  utiliser le frontend
# Poser une question dans le chat
```

**RÃ©sultat attendu** :
- Message utilisateur affichÃ©
- Fallback automatique vers rules-engine
- RÃ©ponse FAQ statique affichÃ©e
- Pas de crash, systÃ¨me continue Ã  fonctionner

---

## ðŸ“¡ API Backend

### POST /api/chat

GÃ©nÃ¨re une rÃ©ponse IA Ã  partir d'un message utilisateur.

**RequÃªte** :
```json
{
  "message": "Comment obtenir une CNI ?",
  "language": "fr",
  "history": []
}
```

**RÃ©ponse** :
```json
{
  "content": "Tu es un assistant pour les services publics...",
  "confidence": 0.5,
  "source": "ai",
  "metadata": {
    "language": "fr",
    "kbEntriesUsed": 2,
    "faqEntriesUsed": 2,
    "ragEnabled": false
  }
}
```

### GET /api/status

Retourne le statut du backend.

**RÃ©ponse** :
```json
{
  "status": "ok",
  "backend": {
    "initialized": true,
    "kbEntries": 2,
    "faqFREntries": 2,
    "faqAREntries": 2
  },
  "uptime": 123.45,
  "timestamp": "2025-12-04T23:35:11.701Z"
}
```

---

## âš™ï¸ Configuration

### Frontend (src/main.js)

```javascript
const CONFIG = {
  MAX_HISTORY_MESSAGES: 30,
  AI_CONTEXT_MESSAGES: 10,
  ENABLE_AI: true,           // â† ActivÃ© pour utiliser le backend
  WELCOME_MESSAGE: true
};
```

### Backend (server.js)

```javascript
const PORT = process.env.PORT || 4000;  // Port du serveur
```

### AI Adapter (src/engine/ai-adapter.js)

```javascript
const API_URL = 'http://localhost:4000/api/chat';  // URL API backend
```

---

## ðŸ”§ Modifications EffectuÃ©es

### Backend

âœ… **Conversion CommonJS â†’ ES Modules**
- `ia/*.cjs` â†’ `ia/*.js`
- `require()` â†’ `import`
- `module.exports` â†’ `export`

âœ… **CrÃ©ation server.js**
- Express + CORS
- POST /api/chat
- GET /api/status
- Gestion erreurs

âœ… **Fonction generateIaResponse()**
- Chargement KB + FAQ
- Construction prompt
- Format rÃ©ponse standardisÃ©

### Frontend

âœ… **ai-adapter.js rÃ©Ã©crit**
- Appels HTTP fetch() vers backend
- DÃ©tection automatique langue (FR/AR)
- Gestion erreurs + fallback null

âœ… **main.js modifiÃ©**
- `ENABLE_AI: true`
- Initialisation backend via initAI()

âœ… **package.json**
- Ajout script `npm run backend`
- DÃ©pendances : express, cors

---

## ðŸ“ Phase 1 : Ce qui fonctionne

âœ… Backend charge KB + FAQ depuis JSON
âœ… Construction de prompts FR/AR avec contexte
âœ… Serveur HTTP expose API /api/chat
âœ… Frontend appelle backend via fetch()
âœ… Fallback automatique vers rules-engine
âœ… Mode dÃ©gradÃ© (backend down) fonctionne
âœ… DÃ©tection automatique langue FR/AR

---

## ðŸš§ Phase 2/3 : Ã€ faire

âŒ **Phase 2 : IntÃ©gration LLM rÃ©el**
- Remplacer stub LLM par TinyLLaMA
- GÃ©nÃ©rer vraies rÃ©ponses (pas juste le prompt)
- Utiliser Transformer.js ou ONNX

âŒ **Phase 3 : RAG avec embeddings**
- Vectorisation de la KB
- Recherche similaritÃ© cosine
- Top-K documents pertinents

---

## ðŸ› DÃ©pannage

### Erreur : "Backend non accessible"

**Cause** : Le backend n'est pas dÃ©marrÃ©

**Solution** :
```bash
npm run backend
```

### Erreur : "CORS policy"

**Cause** : Le frontend et le backend tournent sur des ports diffÃ©rents

**Solution** : Le CORS est dÃ©jÃ  activÃ© dans `server.js`, vÃ©rifier que les deux serveurs tournent

### Le frontend utilise toujours rules-engine

**Cause** : `CONFIG.ENABLE_AI` est Ã  `false`

**Solution** : VÃ©rifier dans `src/main.js` ligne 26 que `ENABLE_AI: true`

### Backend retourne juste le prompt

**C'est normal en Phase 1** ! Le backend retourne le prompt construit pour vÃ©rifier que le pipeline fonctionne. En Phase 2, on intÃ©grera un vrai LLM qui gÃ©nÃ©rera des rÃ©ponses.

---

## ðŸ“š Fichiers Importants

| Fichier | Description |
|---------|-------------|
| [server.js](server.js) | Serveur HTTP backend |
| [ia/app.js](ia/app.js) | Orchestrateur IA + generateIaResponse() |
| [src/engine/ai-adapter.js](src/engine/ai-adapter.js) | Client HTTP frontend |
| [src/main.js](src/main.js) | Point d'entrÃ©e app (CONFIG) |
| [data/kb_services_mauritanie.json](data/kb_services_mauritanie.json) | Base de connaissances |
| [data/faq_fr_rag.json](data/faq_fr_rag.json) | FAQ franÃ§ais |
| [data/faq_ar_rag.json](data/faq_ar_rag.json) | FAQ arabe |

---

## ðŸŽ‰ RÃ©sumÃ©

L'intÃ©gration Phase 1 est **complÃ¨te et fonctionnelle** :

1. âœ… Backend en ES Modules
2. âœ… Serveur HTTP avec Express
3. âœ… API /api/chat fonctionnelle
4. âœ… Frontend connectÃ© au backend
5. âœ… Fallback automatique
6. âœ… Mode dÃ©gradÃ© testÃ©
7. âœ… DÃ©tection langue FR/AR

**Prochaine Ã©tape** : IntÃ©grer TinyLLaMA en Phase 2 pour gÃ©nÃ©rer de vraies rÃ©ponses !

---

**DerniÃ¨re mise Ã  jour** : DÃ©cembre 2025
**Statut** : âœ… Production Ready (Phase 1)
